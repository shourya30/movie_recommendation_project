{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17983c8f",
   "metadata": {},
   "source": [
    "# Metadata-based Recommender\n",
    "We aim to calculate the similarity of the movie content using cosine similarity. Accordingly, we recommend a movie with similar content. In Content-based, we only consider the story description.\n",
    "Here, we improve by calculating cosine similarity from the soup of 'content' and 'metadata' of the movie such as star, director, crew, and genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd672797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "class MergeCleanData:\n",
    "    \n",
    "    def __init__(self, metadata, credits, keywords):\n",
    "\n",
    "        self.df = pd.read_csv(metadata)\n",
    "        self.cred_df = pd.read_csv(credits)\n",
    "        self.key_df = pd.read_csv(keywords)\n",
    "\n",
    "        \n",
    "    def clean_as_int(self, x):\n",
    "        \n",
    "        \"\"\"Function to convert 'x' to integers, if can not, return Nan\"\"\"\n",
    "        \n",
    "        try:\n",
    "            return int(x)\n",
    "        except:\n",
    "            return np.nan\n",
    "        \n",
    "    \n",
    "    def clean_ids(self, df):\n",
    "        \n",
    "        \"\"\"Function to clean df for none-integer data\n",
    "        \n",
    "        Args:\n",
    "            df(object): the dataframe(pandas), which is the dataset\n",
    "            \n",
    "        Return:\n",
    "            df(object): the cleaned data where 'id' was converted as 'int'\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        #Clean the ids of df\n",
    "        df['id'] = df['id'].apply(self.clean_as_int)    \n",
    "                                  \n",
    "        #Filter all rows that have a null ID\n",
    "        df = df[df['id'].notnull()]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def main(self):\n",
    "        \n",
    "        \"\"\"Function to return combineed with 'id' reference\n",
    "        \n",
    "        Args:\n",
    "            none: \n",
    "        \n",
    "        Return:\n",
    "            combined dataframe (object):\n",
    "        \"\"\"\n",
    "        self.df = self.clean_ids(self.df)\n",
    "        self.cred_df = self.clean_ids(self.cred_df)\n",
    "        self.key_df = self.clean_ids(self.key_df)\n",
    "        \n",
    "        # Merge keywords and credits into your main metadata dataframe\n",
    "        self.df = self.df.merge(self.cred_df, on='id')\n",
    "        self.df = self.df.merge(self.key_df, on='id')\n",
    "        \n",
    "        return self.df \n",
    "        \n",
    "class CreateSoup:\n",
    "    \n",
    "    def __init__(self, cleaned_data):\n",
    "        \n",
    "        self.df = cleaned_data\n",
    "        \n",
    "    def get_native_obj(self, df):\n",
    "        \n",
    "        \"\"\"Function to return combineed with 'id' reference\n",
    "        \n",
    "        Args:\n",
    "            df(object): the dataframe(pandas), which is the dataset that contains 'features'\n",
    "        \n",
    "        Return:\n",
    "            dataframe (object): the dataframe that applied 'literal_eval' function\n",
    "        \"\"\"\n",
    "        from ast import literal_eval\n",
    "        \n",
    "        # Convert the stringified objects into the native python objects\n",
    "        features = ['cast', 'crew', 'keywords', 'genres']\n",
    "        \n",
    "        for feature in features:\n",
    "            df[feature] = df[feature].apply(literal_eval)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_director(self, x):\n",
    "        \n",
    "        \"\"\"Function to extract the director's name. If director is not listed, return NaN\"\"\"\n",
    "\n",
    "        for crew_member in x:\n",
    "            if crew_member['job'] == 'Director':\n",
    "                return crew_member['name']\n",
    "        \n",
    "        return np.nan\n",
    "    \n",
    "    def generate_list(self, x, n=3):\n",
    "        \n",
    "        \"\"\"Function to returns the list top 'n' elements or entire list\"\"\"\n",
    "        \n",
    "        if isinstance(x, list):\n",
    "            \n",
    "            names = [i['name'] for i in x]\n",
    "            #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n",
    "            if len(names) > n:\n",
    "                names = names[:n]\n",
    "            return names\n",
    "\n",
    "        #Return empty list in case of missing/malformed data\n",
    "        \n",
    "        return []\n",
    "\n",
    "    def sanitize(self, x):\n",
    "        \n",
    "        \"\"\"Function to sanitize data to prevent ambiguity. It removes spaces and converts to lowercase\"\"\"\n",
    "        \n",
    "        if isinstance(x, list):\n",
    "            #Strip spaces and convert to lowercase\n",
    "            return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "        \n",
    "        else:\n",
    "            #Check if director exists. If not, return empty string\n",
    "            if isinstance(x, str):\n",
    "                return str.lower(x.replace(\" \", \"\"))\n",
    "            else:\n",
    "                return ''\n",
    "    \n",
    "    def create_soup(self, x):\n",
    "        \"\"\"Function that creates a soup out of the desired metadata\"\"\"\n",
    "        \n",
    "        return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\n",
    "\n",
    "    def main(self):\n",
    "        \n",
    "        \"\"\"Function to returns the soup of keywords, genres, cast, directer\"\"\"\n",
    "        \n",
    "        self.df = self.get_native_obj(self.df)\n",
    "        \n",
    "        #Define the new director feature\n",
    "        self.df['director'] =  self.df['crew'].apply(self.get_director)\n",
    "        \n",
    "        #Apply the generate_list function to cast and keywords\n",
    "        self.df['cast'] = self.df['cast'].apply(self.generate_list)\n",
    "        self.df['keywords'] = self.df['keywords'].apply(self.generate_list)\n",
    "        self.df['genres'] = self.df['genres'].apply(self.generate_list)\n",
    "        \n",
    "        #Only consider a maximum of 3 genres\n",
    "        n=3\n",
    "        self.df['genres'] = self.df['genres'].apply(lambda x: x[:n])\n",
    "\n",
    "        #Apply the generate_list function to cast, keywords, director and genres\n",
    "        for feature in ['cast', 'director', 'genres', 'keywords']:\n",
    "            #print(feature)\n",
    "            self.df[feature] = self.df[feature].apply(self.sanitize)\n",
    "            \n",
    "        # Create the new soup feature\n",
    "        self.df['soup'] = self.df.apply(self.create_soup, axis=1)\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "class ContentBasedRecommender:\n",
    "    \n",
    "    def __init__(self, database_soup):\n",
    "        \n",
    "        self.df = database_soup\n",
    "    \n",
    "    def cal_tfidf(self, df, stop_words_list=['english']):\n",
    "        \n",
    "        \"\"\"Function to creat the Term Frequency-Inverse Document Frequency (TF-IDF) matrix\n",
    "\n",
    "        Args:\n",
    "            df(object): the dataframe(pandas), which is the dataset that contain 'overview' documents of movies\n",
    "            stop_words(list): the words that extremly commom in the 'overview' documents of movies\n",
    "        \n",
    "        Return:\n",
    "            tfidf_matrix (tensor): the word vecterized-matrix\n",
    "        \"\"\"\n",
    "        \n",
    "        #Define a TF-IDF Vectorizer Object. Remove all english stopwords\n",
    "        tfidf = TfidfVectorizer(stop_words=stop_words_list)\n",
    "\n",
    "        #Replace NaN with an empty string\n",
    "        df['soup'] = df['soup'].fillna('')\n",
    "\n",
    "        #Construct the required TF-IDF matrix by applying the fit_transform method on the overview feature\n",
    "        tfidf_matrix = tfidf.fit_transform(df['soup'])\n",
    "        \n",
    "        return tfidf_matrix\n",
    "        \n",
    "    def get_cosine_sim(self, tfidf_matrix):\n",
    "        \n",
    "        \"\"\"Function to compute the cosine similarity matrix \n",
    "\n",
    "        Args:\n",
    "            tfidf_matrix (tensor): the word vecterized-matrix\n",
    "        \n",
    "        Return:\n",
    "            cosine similarity matrix(tensor)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute the cosine similarity matrix\n",
    "        cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "        return cosine_sim\n",
    "    \n",
    "    def get_indices(self, df):\n",
    "        \n",
    "        \"\"\"Function to construct a reverse mapping of indices and movie titles, \n",
    "        and drop duplicate titles(if any)\"\"\"\n",
    "        \n",
    "        indices = pd.Series(df.index, index=df['title']).drop_duplicates()\n",
    "        \n",
    "        return indices\n",
    "        \n",
    "    def main(self, title_input, see_top =25):\n",
    "        \n",
    "        \"\"\"Function to takes in movie title as input and gives recommendations\n",
    "        \n",
    "        Args:\n",
    "            title_input (string): the movie name\n",
    "        \n",
    "        Return:\n",
    "            recommendation (object):\n",
    "        \"\"\"\n",
    "    \n",
    "        # Obtain the index of the movie that matches the title\n",
    "        indices = self.get_indices(self.df)\n",
    "        idx = indices[title_input]\n",
    "\n",
    "        # Get the pairwsie similarity scores of all movies with that movie\n",
    "        # And convert it into a list of tuples \n",
    "        tfidf_matrix = self.cal_tfidf(self.df)\n",
    "        cosine_sim = self.get_cosine_sim(tfidf_matrix)\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "        # Sort the movies based on the cosine similarity scores\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Get the scores of the 'see_top' most similar movies. Ignore the first movie(itself).\n",
    "        sim_scores = sim_scores[1:see_top+1]\n",
    "\n",
    "        # Get the movie indices\n",
    "        movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "        # Return the top 10 most similar movies\n",
    "        \n",
    "        return self.df['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d35df59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MMIL\\AppData\\Local\\Temp\\ipykernel_2240\\2323466423.py:11: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.df = pd.read_csv(metadata)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27768                                 The Little Matchgirl\n",
       "33119                                          The Prophet\n",
       "29607                                          Cheburashka\n",
       "40904                   VeggieTales: Josh and the Big Wall\n",
       "40913    VeggieTales: Minnesota Cuke and the Search for...\n",
       "270                                       Man of the House\n",
       "986                                               Infinity\n",
       "29198                                      Superstar Goofy\n",
       "811                            The Adventures of Pinocchio\n",
       "15209             Spiderman: The Ultimate Villain Showdown\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the CSV File into df\n",
    "metadata = r'C:\\Users\\MMIL\\Panithan\\Git_projects\\movies_metadata.csv'\n",
    "credits = r'C:\\Users\\MMIL\\Panithan\\Git_projects\\credits.csv'\n",
    "keywords = r'C:\\Users\\MMIL\\Panithan\\Git_projects\\keywords.csv'\n",
    "\n",
    "prepro = MergeCleanData(metadata, credits, keywords)\n",
    "database = prepro.main()\n",
    "\n",
    "make_soup= CreateSoup(database)\n",
    "database_soup = make_soup.main()\n",
    "\n",
    "recommender= ContentBasedRecommender(database_soup)\n",
    "recommender.main(title_input='The Lion King', see_top =10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ba0ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12696                      Iron Man\n",
       "21033                    Iron Man 3\n",
       "26773       Avengers: Age of Ultron\n",
       "26782    Captain America: Civil War\n",
       "4358                           Made\n",
       "18008                  The Avengers\n",
       "3698                          X-Men\n",
       "6264                             X2\n",
       "26777                       Ant-Man\n",
       "26780                Thor: Ragnarok\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.main(title_input='Iron Man 2', see_top =10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
